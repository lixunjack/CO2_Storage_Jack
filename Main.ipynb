{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b80d217",
   "metadata": {},
   "source": [
    "#### TorchLightening Script for understanding Task 2\n",
    "\n",
    "https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n",
    "\n",
    "- 13, March, 2024\n",
    "- By Jack Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941bdd5d",
   "metadata": {},
   "source": [
    "    IMPORT BASIC PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13bb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "h5py._errors.unsilence_errors()\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "# SUGGESTION: create all folders for storing results\n",
    "if not os.path.exists('./vis'):\n",
    "    os.mkdir('./vis')\n",
    "\n",
    "if not os.path.exists('./vis_results'):\n",
    "    os.mkdir('./vis_results')\n",
    "\n",
    "if not os.path.exists('./model256_weights'):\n",
    "    os.mkdir('./model256_weights')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d608f",
   "metadata": {},
   "source": [
    "    Import Lightning: Import the necessary modules from PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef67ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import albumentations as albu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d1ac6",
   "metadata": {},
   "source": [
    "    Define LightningModule: Create a LightningModule class that inherits from pl.LightningModule. This class will contain your model architecture and training logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e861bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class MyLightningModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = smp.Unet(\n",
    "            encoder_name='resnet34',\n",
    "            encoder_weights=None,\n",
    "            in_channels=4,\n",
    "            classes=1,\n",
    "            activation='sigmoid'\n",
    "        )\n",
    "        self.l2_loss = torch.nn.MSELoss()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, masks = batch\n",
    "        preds = self(imgs).squeeze()\n",
    "        loss = self.l2_loss(preds, masks)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, masks = batch\n",
    "        preds = self(imgs).squeeze()\n",
    "        val_loss = self.l2_loss(preds, masks)\n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "        return val_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b8650",
   "metadata": {},
   "source": [
    "    Define LightningDataModule: If you're using custom data loaders, create a LightningDataModule class that inherits from pl.LightningDataModule. This class will contain your data loading logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f39acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from dataset import MyDataset\n",
    "\n",
    "    \n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, augmentation=None, preprocessing=None, batch_size=4):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.n_training_samples = 12\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        #get the file names\n",
    "        permutations = list(product(range(4), repeat=2))\n",
    "        file_list = []\n",
    "        properties_list = []\n",
    "        for idx1, idx2 in permutations:\n",
    "            file_name = f'256modelruns/Pe1_K1_{idx1}_{idx2}.hdf5'\n",
    "            file_list.append(file_name)\n",
    "\n",
    "        \n",
    "        self.train_dataset = MyDataset(file_list[:self.n_training_samples],self.augmentation[0], self.preprocessing)\n",
    "        \n",
    "        # print(len(self.train_dataset)) \n",
    "        # print(len(self.train_dataset[0])) \n",
    "              \n",
    "        self.val_dataset = MyDataset(file_list[self.n_training_samples:],self.augmentation[1], self.preprocessing)\n",
    "        \n",
    "        # print( len(self.val_dataset) ) \n",
    "        # print(len(self.val_dataset[0]) )  \n",
    "              \n",
    "    def train_dataloader(self):\n",
    "        #train_sampler = RandomSampler(self.train_dataset, replacement=True, num_samples=10000) \n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=1, drop_last=True) # sampler=train_sampler\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=4, num_workers=1, shuffle=False, drop_last=True)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6343461",
   "metadata": {},
   "source": [
    "    Training Loop with Trainer: Create a pl.Trainer object and use it to train your LightningModule.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf5344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.Resize(256, 256),  # not needed\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Resize to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.Resize(256, 256),  \n",
    "    ]\n",
    "    return albu.Compose(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7311b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-03-13 16:02:39.284440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | model   | Unet    | 24.4 M\n",
      "1 | l2_loss | MSELoss | 0     \n",
      "------------------------------------\n",
      "24.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.4 M    Total params\n",
      "97.758    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c9a213c22640098f4125935a2007bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/captainjack/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/captainjack/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf59eb99bcb441f899483803019f00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/captainjack/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import RandomSampler\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pre_processing import get_preprocessing\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "model = MyLightningModel()\n",
    "data_module = MyDataModule(augmentation=[get_training_augmentation(), get_validation_augmentation()], preprocessing=get_preprocessing())\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20)\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
